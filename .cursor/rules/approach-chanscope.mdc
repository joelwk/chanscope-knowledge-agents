---
description: This document outlines the current Chanscope approach, incorporating recent changes related to Replit deployment, advanced data processing, embedding management using Object Storage, and refined query processing logic.
globs: 
alwaysApply: false
---
This document outlines the current Chanscope approach, incorporating recent changes related to Replit deployment, advanced data processing, embedding management using Object Storage, and refined query processing logic.

## 1. Core Philosophy & Architecture

The Chanscope system is designed for analyzing message board data to detect early signals. Key architectural principles include:

-   **Modular Design**: Separate components for data ingestion, sampling, embedding, inference, and API interaction.
-   **Environment Adaptation**: The system dynamically adjusts its behavior based on the detected environment (Local, Docker, Replit), particularly concerning data storage and resource management.
-   **Robustness**: Includes fallback mechanisms (e.g., mock embeddings) and comprehensive error handling.
-   **Reproducibility**: Aims for consistent processing pipelines and clear logging.

## 2. Data Processing Orchestration

### 2.1. Data Lifecycle & Storage

-   **Source**: Data is ingested from S3.
-   **Local/Docker Storage**:
    -   `complete_data.csv`: Stores raw ingested data.
    -   `data/stratified/stratified_sample.csv`: Stores the sampled dataset.
    -   `data/stratified/embeddings.npz`: Stores embeddings in compressed NumPy format.
    -   `data/stratified/thread_id_map.json`: Maps thread IDs to embedding indices.
-   **Replit Storage**:
    -   **Complete Data**: Stored in PostgreSQL (managed via `ReplitDataStorage`).
    -   **Stratified Sample**: Stored in Replit Object Storage (key: `stratified_sample.csv`, managed via `ReplitObjectStorage`).
    -   **Embeddings & Map**: Stored together in Replit Object Storage (key: `embeddings.npz`, managed via `ReplitObjectEmbeddingStorage`). The `.npz` file contains both the `embeddings` array and the `thread_id_map` dictionary.

### 2.2. Initial Data Preparation (On Startup/First Run)

1.  **Data Ingestion**: Fetch data from S3 (from `DATA_RETENTION_DAYS` ago to now).
    -   Local/Docker: Save to `complete_data.csv`.
    -   Replit: Insert into PostgreSQL.
2.  **Stratification**: Create a stratified sample (`stratified_sample.csv`) using `sampler.py`.
    -   Sampling is primarily time-based, potentially using reservoir sampling for large datasets.
    -   The `filter_date` parameter can restrict the time window for sampling.
    -   Replit: Sample saved to Object Storage.
3.  **Embedding Generation**: Create embeddings for the stratified sample using `embedding_ops.py`.
    -   Embeddings are generated via the configured `DEFAULT_EMBEDDING_PROVIDER`.
    -   Handles batching (`embedding_batch_size`) and retries.
    -   Includes fallback to mock embeddings if API fails or `USE_MOCK_EMBEDDINGS=true`.
    -   Replit: Embeddings (`.npz`) and map saved atomically to Object Storage.

### 2.3. Data Refresh (`scheduled_update.py` / API `force_refresh`)

-   **`force_refresh=true`**:
    1.  **Ingestion Check (Local/Docker)**: Verify `complete_data.csv` exists and is current. If so, skip S3 refresh. Replit uses DB count.
    2.  **Stratification**: Regenerate `stratified_sample.csv` (and save to appropriate storage).
    3.  **Embedding Generation**: Regenerate `embeddings.npz` and `thread_id_map.json` (and save). Can be skipped with `--skip-embeddings`.
-   **`force_refresh=false` (Default)**:
    1.  **Readiness Check**: Verify essential data exists (DB rows/`complete_data.csv`, stratified sample, embeddings).
        -   Replit: Checks PostgreSQL row count and Object Storage for sample/embeddings.
    2.  **No Regeneration**: Use existing stratified data and embeddings. If essential data is missing, implicitly triggers a refresh.
-   **Advanced Refresh Options**:
    -   `--skip-embeddings`: Refresh sample but not embeddings.
    -   `--filter-date`: Apply a start date filter during refresh/sampling.
    -   `embeddings` command: Generate embeddings for the existing sample.
    -   `status` command: Check data readiness and configuration.

## 3. Embedding Management

-   **Format**: `.npz` (compressed NumPy) stores both `embeddings` array and `metadata` (including dimensions, count, creation time, mock status).
-   **Storage**: Filesystem (Local/Docker) or Replit Object Storage.
-   **Mapping**: `thread_id_map.json` (Local/Docker) or included within `.npz` metadata (Replit) maps `thread_id` to the embedding array index.
-   **Loading**: `load_embeddings` and `load_thread_id_map` handle loading from the appropriate storage backend (filesystem or Replit Object Storage).
-   **Validation**: Text is validated (`validate_text_for_embedding`) before embedding. Embeddings are checked for correct dimensions and format.
-   **Atomic Saves**: Embeddings are saved atomically (temp file -> rename) to prevent corruption.
-   **Mock Embeddings**: Generated deterministically based on `thread_id` hash if API fails or explicitly requested (`USE_MOCK_EMBEDDINGS=true` or `DEFAULT_EMBEDDING_PROVIDER=mock`). Metadata in `.npz` indicates if embeddings are mock.

## 4. Query Processing

### 4.1. Standard Query (`/api/v1/query`)

1.  **Data Readiness Check (Replit)**: Before processing, check if data (DB rows, stratified sample, embeddings) is ready in Replit storage. If not, or if `force_refresh=true`, trigger `ensure_data_ready`.
2.  **Semantic Search**:
    -   Generate embedding for the input query.
    -   Use `strings_ranked_by_relatedness` (or `recursive_...` variant) in `inference_ops.py` to find the `top_n` most similar chunks from the loaded embeddings using cosine similarity. Handles various stored embedding formats (JSON string, list, numpy array).
3.  **Chunk Processing**:
    -   Use `generate_chunks_batch` (or `generate_chunks` if `use_batching=false`) in `model_ops.py` to process the text of the retrieved chunks via the `DEFAULT_CHUNK_PROVIDER`. Handles batching (`chunk_batch_size`).
4.  **Summarization**:
    -   Use `generate_summaries_batch` (or `generate_summary`) to combine chunk analyses and the original query into a final summary using the `DEFAULT_SUMMARY_PROVIDER` and `prompt.yaml`. Handles batching (`summary_batch_size`). Includes temporal context.
5.  **Response**: Return structured response including processed chunks, final summary, and metadata (processing time, counts, etc.).

### 4.2. Recent Data Query (`/api/v1/process_recent_query`)

-   Specifically targets data within a recent time window (default: last 6 hours, configurable via `filter_date` parameter).
-   Loads a predefined query (e.g., from `stored_queries.yaml` or a default).
-   Performs the Replit data readiness check (similar to standard query).
-   Applies the time filter *before* semantic search if possible, or filters results post-search.
-   Follows the same chunk processing and summarization steps as the standard query.

## 5. Generative Pipeline Behavior (Core Logic)

This remains consistent with the previous version:

1.  **Data Preparedness:** Ensure stratified data and `.npz` embeddings are available and loadable.
2.  **Query Execution:** Perform semantic search using cosine similarity on embeddings.
3.  **Chunk Processing:** Summarize each relevant chunk using the chunk LLM.
4.  **Final Aggregation:** Combine chunk summaries and query using the summary LLM and `prompt.yaml`.
5.  **Response Generation:** Return chunks, summary, and metadata.

## 6. Deployment Considerations

-   **Docker**: Uses Docker volumes for persistence. Requires standard environment variables (`OPENAI_API_KEY`, etc.). Resource limits set in `docker-compose.yml`.
-   **Replit**:
    -   Uses Replit Secrets for sensitive keys (`OPENAI_API_KEY`, `AWS_*`, etc.).
    -   Uses `.replit` or Replit Environment UI for non-sensitive variables (`DATA_RETENTION_DAYS`, `ENABLE_DATA_SCHEDULER`, etc.).
    -   Storage managed via PostgreSQL and Object Storage (see 2.1).
    -   Entry point configured via `.replit` (`run` command).
    -   Requires `replit.nix` for system dependencies.
    -   Resource constraints may necessitate smaller batch sizes or optimized processing (handled partly by environment detection).

## 7. Testing and Validation

-   **Framework**: `pytest` with dedicated test scripts (`test_*.py`).
-   **Environment-Specific Tests**: `run_tests.sh` detects the environment (Local, Docker, Replit) and runs appropriate test suites or configurations.
    -   Replit tests use specific environment variables (`REPLIT_ENV`, `REPL_ID`, `TEST_MODE`) and potentially resource-optimized settings (lower batch sizes/workers). See `run_replit_tests` in `run_tests.sh`.
-   **Key Validations**:
    -   Initial data load and preparation (ingestion, stratification, embedding).
    -   Embedding generation correctness (`.npz` format, mock fallback).
    -   `force_refresh` logic (True vs. False).
    -   End-to-end generative pipeline execution.
    -   Correct data handling in different environments (filesystem vs. Replit storage).
-   **Output**: Comprehensive logs and structured test results.

---

This updated approach reflects the system's current capabilities, including environment-specific adaptations for Replit, advanced data refresh controls, and robust embedding management using Object Storage.