---
description: This document outlines the guidelines for testing the Chanscope application, ensuring that test implementation aligns with the core Chanscope approach. It covers the data processing pipeline, query behavior, deployment processes, and more.
globs: */tests/**/*.py,*/scripts/run_*tests.sh,*/scripts/validate_chanscope_approach.py
alwaysApply: false
---
# Chanscope Testing Rules


This document outlines the guidelines for testing the Chanscope application, ensuring that test implementation aligns with the core Chanscope approach. It covers the data processing pipeline, query behavior, deployment processes, and more.

---

## Description

These rules define the requirements and best practices for testing the Chanscope application. They address unit, integration, performance, and security testing, ensuring that each test validates a specific part of the Chanscope approach while being executable in various environments (local, Docker, Replit).

---

## File Patterns

The following glob patterns determine the files to which these rules apply:

```
**/tests/**/*.py
**/scripts/run_*tests.sh
**/scripts/validate_chanscope_approach.py
```


---

## Test Suite Organization

### 1. Core Test Categories

Tests must be organized to validate all key components of the Chanscope approach:

- **Data Ingestion Tests:**  
  Verify S3 data fetching, retention logic, and initial data load (e.g., `test_data_ingestion.py`).

- **Data Stratification Tests:**  
  Validate sampling algorithms and data representation accuracy.

- **Embedding Generation Tests:**  
  Ensure proper embedding creation, storage, and consistency (e.g., `test_embedding_pipeline.py`).

- **Query Processing Tests:**  
  Validate both forced refresh and standard modes:
  - **Force Refresh Mode:** Ensure data freshness, re-stratification, and regeneration of embeddings.
  - **Standard Mode:** Verify that existing embeddings are used and fallback logic is applied if necessary.

- **API Availability Tests:**  
  Verify API endpoints remain responsive even during data initialization, with appropriate status indicators.

- **End-to-End Tests:**  
  Validate the complete Chanscope approach implementation (e.g., `test_chanscope_approach.py`).

- **Component Integration Tests:**  
  Validate integration between data ingestion, stratification, embedding generation, search, chunk retrieval, and final summarization.

- **Startup Data Loading Tests:**  
  Verify health check behavior, initialization state detection, and progress monitoring during data loading delays.

### 2. Test Script Requirements

All test scripts must:

- Be executable in isolated environments (Docker, local, or Replit).
- Include proper setup and teardown routines to avoid interference.
- Generate clear, structured logs and output.
- Return appropriate exit codes for CI/CD integration.

### 3. Cross-Platform Compatibility

Test scripts must be designed for use across multiple platforms:

- **Linux/macOS:**  
  Use standard bash scripts (e.g., `*.sh`).

- **Windows:**  
  Provide PowerShell equivalents or ensure compatibility by:
  - Using backslashes for file paths.
  - Replacing bash-specific commands with PowerShell equivalents.
  - Handling line endings (CRLF vs LF) properly.
  - Adapting Docker commands to Windows path conventions (e.g., `C:/path` vs `/c/path`).

---

## Test Execution Framework

### 1. Standard Test Execution

Use the `run_tests.sh` script to execute tests locally:

```bash
# Run all tests
scripts/run_tests.sh --all

# Run specific test categories
scripts/run_tests.sh --data-ingestion
scripts/run_tests.sh --embedding
scripts/run_tests.sh --endpoints
scripts/run_tests.sh --chanscope-approach

# Display help and options
scripts/run_tests.sh --help
```

### 2. Docker-Based Testing

For containerized testing, use the dedicated test Docker configuration:

```bash
# Navigate to deployment directory
cd deployment

# Run all tests in Docker
docker-compose -f docker-compose.test.yml build
docker-compose -f docker-compose.test.yml up

# From project root (alternative)
docker-compose -f deployment/docker-compose.test.yml build
docker-compose -f deployment/docker-compose.test.yml up
```

### 3. Test Configuration Settings

The following environment variables control test behavior:

```bash
# Enable test mode
TEST_MODE=true                    # Enable test-specific configurations
USE_MOCK_DATA=true                # Use mock data instead of real S3 data
USE_MOCK_EMBEDDINGS=true          # Use mock embeddings instead of calling real APIs

# Test execution options
AUTO_CHECK_DATA=true              # Enable data checking during tests
RUN_TESTS_ON_STARTUP=true         # Run tests during container startup
TEST_TYPE=all                     # Specify which tests to run
```

**Considerations:**

- **Resource Contention:** Running tests with application startup may compete for resources.
- **Data Integrity Risks:** Lack of isolation may lead to data modification or corruption.
- **Debugging Complexity:** Combining startup and testing can complicate troubleshooting.

**Recommendation:** Prefer dedicated testing environments using `docker-compose.test.yml` for isolated testing.

---

## Validation Against Chanscope Approach

### 1. Initial Data Load Validation

Tests must ensure that on startup:

- Data is correctly ingested from S3.
- Data is properly stratified.
- Embeddings are generated as expected.

Example (pseudo-code):

```python
def test_initial_data_load():
    # Arrange: Prepare clean environment and mock S3
    # Act: Trigger application startup
    # Assert: Verify that complete_data.csv, stratified data, and embeddings exist
```

### 2. Query Behavior Validation

Tests must cover both query modes:

#### 2.1 Force Refresh Mode

- Verify that when `force_refresh=true`:
  - Data freshness is checked.
  - A new stratified sample is generated.
  - New embeddings are created.
  - Queries yield appropriate chunks and summaries.

#### 2.2 Standard Mode

- Verify that when `force_refresh=false`:
  - Existing embeddings are used (without regeneration).
  - Query processing returns expected results.
  - If data is missing, fallback to force refresh behavior.

### 3. Component Integration Tests

Ensure that tests validate the integration between:

- Data ingestion and stratification.
- Stratification and embedding generation.
- Embedding search and chunk retrieval.
- Chunk processing and final summarization.

### 4. Startup Data Loading Tests

Tests must address:

- **Health Check Testing:** Validate health checks during initialization.
- **Initialization State Detection:** Confirm the application reports its initialization state correctly.
- **API Availability:** Verify API remains responsive even during initialization.
- **Background Processing:** Confirm data processing continues in the background without blocking API.
- **Progress Monitoring:** Ensure that data loading progress is logged and tracked.

Example (pseudo-code):

```python
def test_health_during_initialization():
    # Arrange: Start application with mock S3 data and AUTO_CHECK_DATA=false
    # Act: Query health endpoint immediately after startup
    # Assert: Verify health endpoint returns "healthy" status even during initialization
```

### 5. AUTO_CHECK_DATA Setting Tests

Tests must verify the behavior with different AUTO_CHECK_DATA settings:

```python
def test_auto_check_data_false():
    # Arrange: Start application with AUTO_CHECK_DATA=false
    # Act: Query API immediately after startup
    # Assert: API responds properly even before data processing completes
    # Assert: Background data processing continues as expected

def test_auto_check_data_true():
    # Arrange: Start application with AUTO_CHECK_DATA=true
    # Act: Monitor startup behavior
    # Assert: API waits for data processing before becoming available
    # Assert: Health checks respond appropriately during initialization
```

---

## Deployment Test Requirements

### 1. Docker Test Environment

Tests must validate Docker-specific elements:

- **Volume Mounting and Permissions:**  
  - Use Docker volumes (not bind mounts) for data directories.
  - Set proper permissions (e.g., chmod -R 777) for directories such as `/app/data`, `/app/data/stratified`, `/app/data/shared`, `/app/logs`, and `/app/temp_files`.

- **Environment Variable Handling:**  
  - Ensure environment variables are properly set (e.g., `TEST_MODE=true`).

- **Service Startup and Orchestration:**  
  - Validate that the docker-compose configuration overrides the default command to run tests.
  - Disable health check and auto-restart during tests to prevent interference.

### 2. CI/CD Integration

Test scripts must be compatible with automated CI/CD pipelines, including:

- Clear indicators of success/failure.
- Detailed error reporting.
- Standardized output formats.
- Appropriate timeouts for long-running tests.

Example CI snippet:

```yaml
test:
  stage: test
  script:
    - docker-compose -f deployment/docker-compose.test.yml build
    - docker-compose -f deployment/docker-compose.test.yml run --rm chanscope-test
  artifacts:
    paths:
      - test_results/
```

### 3. Multi-Environment Testing

Ensure tests are valid across all target environments:

- **Local Development:** Validate with local scripts and environment variables.
- **Docker Container:** Validate containerized execution.
- **Replit Hosting:** Ensure compatibility and proper environment variable usage.

#### 3.1 Environment Detection and Adaptation

Test scripts should:

- Detect the current environment (Docker, Local, or Replit).
- Adapt file paths and configurations accordingly.
- Handle file system permission differences.
- Use environment variables suited for each context.

---

## Environment Setup for Testing

### 1. Local Environment Setup

```bash
# Clone the repository
git clone https://github.com/your-org/chanscope.git
cd chanscope

# Create and populate .env file with required variables (AWS, OpenAI, etc.)
cp .env.example .env

# Make scripts executable
chmod +x scripts/*.sh deployment/*.sh

# Run tests
scripts/run_tests.sh --all
```

### 2. Docker Environment Setup

```bash
# Clone the repository
git clone https://github.com/your-org/chanscope.git
cd chanscope/deployment

# Create and populate .env file
cp .env.example .env

# Run tests in Docker
docker-compose -f docker-compose.test.yml up
```

### 3. Replit Environment Setup

```bash
# Set environment variables in Replit Secrets:
# OPENAI_API_KEY, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION, S3_BUCKET

# Run tests
bash scripts/run_tests.sh --all
```

---

## Test Data Management

### 1. Test Fixtures

- Use consistent test data across suites, covering both typical and edge cases.
- Store test data in version control when practical.

### 2. Mock Services

- **Mock External Dependencies:**  
  Use mocks for services such as S3 and the OpenAI API to isolate tests.
- **Document Mock Behavior:**  
  Ensure that the behavior of mocks is well-documented for maintainability.

### 3. Mock Embeddings

- Set `USE_MOCK_EMBEDDINGS=true` to bypass external embedding models.
- Ensure mock embeddings have consistent dimensions (e.g., 3072) for reproducibility.
- Document in test results how mocks are used versus real embeddings.

```bash
# Enable mock embeddings for testing
export USE_MOCK_EMBEDDINGS=true

# Run embedding tests with mock embeddings
scripts/run_tests.sh --embedding
```

---

## Performance Testing

Include tests to validate performance criteria:

- **Data Refresh Performance:**  
  Measure time required to refresh data under various conditions.
- **Query Response Time:**  
  Validate that query response times meet established thresholds (with and without caching).
- **Resource Utilization:**  
  Monitor CPU and memory usage during intensive operations.
- **API Responsiveness During Data Processing**
  Measure API response times during background data processing.

### Performance Metrics Collection

Tests should capture:

- Time for data stratification.
- Time for embedding generation.
- Query response times.
- Memory usage during peak operations.
- API availability during background processing.

```bash
# Enable performance testing mode
export PERFORMANCE_TEST=true
export ITERATIONS=10

# Run performance tests
scripts/run_tests.sh --chanscope-approach
```

---

## Security and Error Handling Tests

- **Authentication Tests:**  
  Validate API security and access controls.
- **Error Handling Tests:**  
  Verify that failures occur gracefully and resources are cleaned up.
- **Resource Cleanup:**  
  Ensure that temporary files and connections are properly disposed of after tests.

### Common Validation Issues

Tests should verify handling of:

- Short text articles below the minimum threshold.
- Articles with low character diversity.
- Invalid or corrupted data.
- Connection failures to external services.
- Partially processed data scenarios.

---

## Logging and Monitoring

### 1. Centralized Logging

- All tests must use the centralized logging configuration (`config/logging_config.py`).
- Avoid direct calls to `logging.basicConfig()` within test code.
- Ensure log files are written to `/app/logs` and that utility logs (e.g., `utility_func.log`) are correctly redirected.

### 2. Log Consolidation

Tests should verify that:

- Logs are written to the correct directory.
- No logs appear in the application root.
- Log rotation is configured properly.
- Log levels are enforced as per configuration.

Example (pseudo-code):

```python
def test_log_configuration():
    # Arrange: Set up logging environment with controlled log level
    # Act: Generate logs at various levels
    # Assert: Confirm logs are in /app/logs with correct formatting and rotation
```

---

## Troubleshooting Common Issues

### 1. AWS Credential Issues

If tests fail due to AWS credentials:

1. Confirm that the `.env` file has correct credentials.
2. Check that environment variables are properly set in the shell or Docker.
3. Verify that S3_BUCKET is accessible.
4. Consider using mock data by setting `export USE_MOCK_DATA=true`.

### 2. Test Output and Logs

For diagnosing issues:

```bash
# View Docker test logs
cat test_results/chanscope_tests_docker_*.log

# View application logs
cat logs/app.log

# View scheduler logs
cat data/logs/scheduler.log
```

### 3. Docker Volume Issues

If Docker volumes encounter permission issues:

1. Use the test Docker configuration that correctly sets up volumes.
2. Verify volume mappings in docker-compose files.
3. Ensure the Docker user (or 'nobody') has appropriate permissions.

### 4. Windows-Specific Issues

- Adapt file paths (backslashes vs forward slashes).
- Convert CRLF to LF for scripts using `.gitattributes`.
- Adjust script execution policies if necessary (e.g., using PowerShell).
- Ensure you're running docker-compose commands from the deployment directory or specifying the full path.

### 5. "No Configuration File Found" Error

If you encounter "no configuration file provided: not found" error:
1. Make sure you're running docker-compose from the deployment directory:
   ```
   cd deployment
   docker-compose logs -f
   ```
2. Or specify the full path to the docker-compose file:
   ```
   docker-compose -f deployment/docker-compose.yml logs -f
   ```

### 6. Container Restart Loops

If container keeps restarting:
1. Set `AUTO_CHECK_DATA=false` in the environment configuration
2. Check logs for specific error messages
3. Verify S3 connectivity and credentials
4. Ensure volume permissions are correct

### 7. API Unavailability During Data Processing

If the API is unavailable during data processing:
1. Verify `AUTO_CHECK_DATA=false` is set
2. Check the health check configuration (start_period, interval, retries)
3. Review logs for initialization issues
4. Consider increasing the container's resource allocation