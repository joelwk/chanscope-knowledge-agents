modules = ["python-3.11", "postgresql-16"]
hidden = [".pythonlibs"]
run = "bash scripts/replit_init.sh && python -m uvicorn api.app:app --host 0.0.0.0 --port 8080 --log-level info"
entrypoint = "api/app.py"

# =============================================
# Nix Configuration
# =============================================
[nix]
channel = "stable-23_11"
packages = ["arrow-cpp", "cargo", "glibcLocales", "libiconv", "libxcrypt", "libyaml", "openssl", "pgadmin4", "pkg-config", "rustc", "xsimd"]

# =============================================
# Environment Variables
# =============================================
[env]
REPLIT_ENV = "replit"
DEPLOYMENT_ENV = "replit"
API_PORT = "8080"
API_HOST = "0.0.0.0"
LOG_LEVEL = "INFO"
AUTO_CHECK_DATA = "false"    # Don't auto-check data on startup
FORCE_DATA_REFRESH = "false"
SKIP_EMBEDDINGS = "false"
PYTHONPATH = "${REPL_HOME}"
PYTHONUNBUFFERED = "1"
AUTO_REFRESH_MANAGER = "true"  # Auto-start refresh manager with the API
DATA_REFRESH_INTERVAL = "3600"  # Seconds between automatic refresh runs
PIP_NO_CACHE_DIR = "1"

# Legacy scheduler (disabled when using refresh manager; enable only if needed)
ENABLE_DATA_SCHEDULER = "false"
DATA_UPDATE_INTERVAL = "3600"
DATA_RETENTION_DAYS = "5"     # Keep data for 14 days

# Testing Configuration
TEST_MODE = "false"           # Default to false for deployment
USE_MOCK_DATA = "false"
USE_MOCK_EMBEDDINGS = "false"

# Package caching safety (prevent deployment dependency issues)
REPLIT_KEEP_PACKAGE_DEV_DEPENDENCIES = "1"
REPLIT_DISABLE_PACKAGE_LAYER = "0"         # Keep caching enabled by default

# =============================================
# Deployment Configuration
# =============================================
[deployment]
run = "bash scripts/replit_init.sh && python -m uvicorn api.app:app --host 0.0.0.0 --port 8080 --log-level info"
deploymentTarget = "cloudrun"

# =============================================
# Health Check Configuration
# =============================================
[deployment.healthCheck]
path = "/"               # Root path for fastest possible health check
port = 8080
initialDelay = 10        # Reduced - server should start quickly now
timeout = 5              # Standard timeout
period = 10              # Check every 10 seconds
consecutiveSuccesses = 1
consecutiveFailures = 3  # Less tolerant now that startup is fast

[[ports]]
localPort = 8080
externalPort = 443

# =============================================
# Language Configuration
# =============================================
[languages]

[languages.python3]
pattern = "**/*.py"
syntax = "python"

[languages.python3.languageServer]
start = "pylsp"

# =============================================
# Package Manager Configuration
# =============================================
[packager]
language = "python3"

[packager.features]
packageSearch = true
guessImports = true

# =============================================
# UPM Configuration
# =============================================
[unitTest]
language = "python3"

# =============================================
# Interpreter Configuration
# =============================================
[interpreter]
command = ["python3", "-u"]

[workflows]
runButton = "Force a complete data refresh including stratification and embeddings"

[[workflows.workflow]]
name = "test"
mode = "sequential"
author = 38779469

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "bash scripts/run_tests.sh --env=replit"

[[workflows.workflow]]
name = "Check DB"
mode = "sequential"
author = 38779469

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python scripts/check_replit_db.py"

[[workflows.workflow]]
name = "Wipe all data"
mode = "sequential"
author = 38779469

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python scripts/wipe_all_data.py"

[[workflows.workflow]]
name = "Force a complete data refresh including stratification and embeddings"
mode = "sequential"
author = 38779469

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python scripts/process_data.py --force-refresh"

[[workflows.workflow]]
name = "Interactive NL Query"
author = 38779469
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python scripts/interactive_nl_query.py"

[[workflows.workflow]]
name = "Project"
mode = "parallel"
author = "agent"

[[workflows.workflow.tasks]]
task = "workflow.run"
args = "Refresh Dashboard"

[[workflows.workflow]]
name = "Refresh Dashboard"
author = "agent"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python api/refresh_dashboard.py"
waitForPort = 5000

[workflows.workflow.metadata]
outputType = "webview"

[[workflows.workflow]]
name = "Deploy"
mode = "sequential"
author = 38779469

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "bash scripts/replit_init.sh && python -m uvicorn api.app:app --host 0.0.0.0 --port 8080 --log-level info"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python scripts/refresh_control.py start"

[server]
host = "0.0.0.0"
port = 8080

# Commands for Replit interface
[commands.test]
description = "Run tests in Replit environment"
command = "bash scripts/test.sh replit"

[commands.run-api]
description = "Run the API server"
command = "python -m uvicorn api.app:app --host 0.0.0.0 --port 8080"

[commands.update-data]
description = "Run manual data update"
command = "python scripts/scheduled_update.py refresh"

[commands.check-db]
description = "Check Replit database connectivity"
command = "python scripts/check_replit_db.py"

[commands.initialize]
description = "Initialize Replit environment"
command = "bash scripts/replit_init.sh"

[commands.process-data]
description = "Process data stratification and embeddings"
command = "python scripts/process_data.py"

[commands.check-data-status]
description = "Check the status of data processing pipeline"
command = "python scripts/process_data.py --check"

[commands.force-data-refresh]
description = "Force a complete data refresh including stratification and embeddings"
command = "python scripts/process_data.py --force-refresh"

[commands.test-stratification]
description = "Test the stratification and embedding processes directly"
command = "python scripts/test_stratification.py"

[commands.test-stratification-only]
description = "Test only the stratification process"
command = "python scripts/test_stratification.py --stratification-only"

[commands.test-embeddings-only]
description = "Test only the embedding generation process"
command = "python scripts/test_stratification.py --embeddings-only"

# Scheduler Commands
[commands.scheduler-start]
description = "Start the data scheduler"
command = "python scripts/scheduled_update.py refresh --continuous --interval=3600"

[commands.scheduler-status]
description = "Check the status of the data scheduler"
command = "ps aux | grep scheduled_update.py"

[commands.scheduler-logs]
description = "View the scheduler logs"
command = "tail -n 50 logs/scheduler.log"

[replit]
bucket = "rolling-data"

[agent]
expertMode = true

[objectStorage]
defaultBucketID = "replit-objstore-21e6f39c-a3d9-4156-b809-0c4a0efc2d66"
